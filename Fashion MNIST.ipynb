{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_data = np.array(pd.read_csv(r'C:\\\\Users\\Mustafa\\Jupyter Notebook work\\CNN Learning\\dataset\\fashion-mnist_train.csv'))\n",
    "test_data = np.array(pd.read_csv(r'C:\\\\Users\\Mustafa\\Jupyter Notebook work\\CNN Learning\\dataset\\fashion-mnist_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 6, ..., 8, 8, 7], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig = train_data[:, 1:785]\n",
    "y_train_orig = train_data[:, 0]\n",
    "X_test = train_data[:, 1:785]\n",
    "y_test = train_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e0146a4780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnl9JNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e0152dccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation='relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 468,874\n",
      "Trainable params: 468,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.6272 - acc: 0.7828 - val_loss: 0.4493 - val_acc: 0.8470\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.4106 - acc: 0.8547 - val_loss: 0.4164 - val_acc: 0.8484\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3671 - acc: 0.8708 - val_loss: 0.3805 - val_acc: 0.8640\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3370 - acc: 0.8794 - val_loss: 0.3270 - val_acc: 0.8863\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.3176 - acc: 0.8855 - val_loss: 0.3225 - val_acc: 0.8814\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2969 - acc: 0.8933 - val_loss: 0.3305 - val_acc: 0.8828\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 10us/step - loss: 0.2811 - acc: 0.8974 - val_loss: 0.3174 - val_acc: 0.8868\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2696 - acc: 0.9022 - val_loss: 0.3100 - val_acc: 0.8842\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2556 - acc: 0.9066 - val_loss: 0.2938 - val_acc: 0.8978\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2506 - acc: 0.9077 - val_loss: 0.2882 - val_acc: 0.8980\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2358 - acc: 0.9140 - val_loss: 0.2949 - val_acc: 0.8937\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2275 - acc: 0.9159 - val_loss: 0.2880 - val_acc: 0.8959\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2181 - acc: 0.9195 - val_loss: 0.3109 - val_acc: 0.8944\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2117 - acc: 0.9227 - val_loss: 0.2891 - val_acc: 0.8952\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.2060 - acc: 0.9240 - val_loss: 0.2927 - val_acc: 0.8979\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.1960 - acc: 0.9275 - val_loss: 0.2866 - val_acc: 0.9004\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.1890 - acc: 0.9301 - val_loss: 0.3277 - val_acc: 0.8877\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.1839 - acc: 0.9325 - val_loss: 0.2895 - val_acc: 0.8979\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.1783 - acc: 0.9347 - val_loss: 0.2927 - val_acc: 0.8971\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 0s 10us/step - loss: 0.1775 - acc: 0.9350 - val_loss: 0.2919 - val_acc: 0.8983\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.180793094941\n",
      "Test accuracy: 0.934983333333\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.6416 - acc: 0.7801 - val_loss: 0.4278 - val_acc: 0.8454\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3875 - acc: 0.8643 - val_loss: 0.3572 - val_acc: 0.8738\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3405 - acc: 0.8809 - val_loss: 0.3264 - val_acc: 0.8872\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3111 - acc: 0.8907 - val_loss: 0.2997 - val_acc: 0.8945\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2910 - acc: 0.8975 - val_loss: 0.3004 - val_acc: 0.8928\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2798 - acc: 0.8999 - val_loss: 0.2747 - val_acc: 0.9043\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2632 - acc: 0.9055 - val_loss: 0.2694 - val_acc: 0.9043\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2486 - acc: 0.9115 - val_loss: 0.2697 - val_acc: 0.9045\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2402 - acc: 0.9155 - val_loss: 0.2544 - val_acc: 0.9093\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2276 - acc: 0.9183 - val_loss: 0.2470 - val_acc: 0.9115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e014dbba90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2244 - acc: 0.9188 - val_loss: 0.2528 - val_acc: 0.9103\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2090 - acc: 0.9256 - val_loss: 0.2457 - val_acc: 0.9133\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2011 - acc: 0.9283 - val_loss: 0.2459 - val_acc: 0.9119\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1947 - acc: 0.9301 - val_loss: 0.2392 - val_acc: 0.9145\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1871 - acc: 0.9338 - val_loss: 0.2461 - val_acc: 0.9101\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1808 - acc: 0.9352 - val_loss: 0.2307 - val_acc: 0.9183\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1728 - acc: 0.9383 - val_loss: 0.2318 - val_acc: 0.9172\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1665 - acc: 0.9398 - val_loss: 0.2352 - val_acc: 0.9204\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1583 - acc: 0.9428 - val_loss: 0.2428 - val_acc: 0.9140\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1585 - acc: 0.9435 - val_loss: 0.2308 - val_acc: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e014dbbf98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 43us/step\n",
      "Test loss: 0.147866875121\n",
      "Test accuracy: 0.949166666667\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 10s 107ms/step - loss: 0.4744 - acc: 0.8257 - val_loss: 0.4110 - val_acc: 0.8471\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.4087 - acc: 0.8487 - val_loss: 0.3926 - val_acc: 0.8558\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3913 - acc: 0.8554 - val_loss: 0.3695 - val_acc: 0.8653\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3762 - acc: 0.8606 - val_loss: 0.3602 - val_acc: 0.8694\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3690 - acc: 0.8635 - val_loss: 0.3548 - val_acc: 0.8659\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3559 - acc: 0.8683 - val_loss: 0.3412 - val_acc: 0.8711\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3465 - acc: 0.8708 - val_loss: 0.3425 - val_acc: 0.8713\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3478 - acc: 0.8707 - val_loss: 0.3285 - val_acc: 0.8764\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3360 - acc: 0.8768 - val_loss: 0.3412 - val_acc: 0.8758\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3339 - acc: 0.8777 - val_loss: 0.3200 - val_acc: 0.8790\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3330 - acc: 0.8763 - val_loss: 0.3241 - val_acc: 0.8787\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3290 - acc: 0.8781 - val_loss: 0.3383 - val_acc: 0.8736\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.3226 - acc: 0.8802 - val_loss: 0.3130 - val_acc: 0.8841\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.3168 - acc: 0.8833 - val_loss: 0.3133 - val_acc: 0.8840\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.3138 - acc: 0.8829 - val_loss: 0.3069 - val_acc: 0.8851\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.3115 - acc: 0.8847 - val_loss: 0.3166 - val_acc: 0.8814\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.3076 - acc: 0.8854 - val_loss: 0.3153 - val_acc: 0.8821\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.3098 - acc: 0.8853 - val_loss: 0.2999 - val_acc: 0.8923\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.3036 - acc: 0.8864 - val_loss: 0.3035 - val_acc: 0.8881\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.3034 - acc: 0.8883 - val_loss: 0.2977 - val_acc: 0.8922\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.2982 - acc: 0.8895 - val_loss: 0.2886 - val_acc: 0.8974\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2955 - acc: 0.8906 - val_loss: 0.3013 - val_acc: 0.8886\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2953 - acc: 0.8909 - val_loss: 0.3040 - val_acc: 0.8868\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.2954 - acc: 0.8903 - val_loss: 0.2893 - val_acc: 0.8938\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.2904 - acc: 0.8923 - val_loss: 0.2814 - val_acc: 0.8986\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.2894 - acc: 0.8917 - val_loss: 0.2834 - val_acc: 0.8988\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2824 - acc: 0.8964 - val_loss: 0.2982 - val_acc: 0.8904\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2885 - acc: 0.8925 - val_loss: 0.2916 - val_acc: 0.8928\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2842 - acc: 0.8962 - val_loss: 0.2793 - val_acc: 0.8966\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2851 - acc: 0.8938 - val_loss: 0.2864 - val_acc: 0.8933\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2849 - acc: 0.8952 - val_loss: 0.2844 - val_acc: 0.8943\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2787 - acc: 0.8963 - val_loss: 0.2895 - val_acc: 0.8908\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2758 - acc: 0.8966 - val_loss: 0.3025 - val_acc: 0.8852\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2799 - acc: 0.8968 - val_loss: 0.2802 - val_acc: 0.8981\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2778 - acc: 0.8973 - val_loss: 0.2896 - val_acc: 0.8925\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2709 - acc: 0.8989 - val_loss: 0.2665 - val_acc: 0.9006\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2716 - acc: 0.9002 - val_loss: 0.2764 - val_acc: 0.8961\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2672 - acc: 0.9010 - val_loss: 0.2748 - val_acc: 0.9003\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2653 - acc: 0.9019 - val_loss: 0.2774 - val_acc: 0.8951\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2661 - acc: 0.9025 - val_loss: 0.2693 - val_acc: 0.8996\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2621 - acc: 0.9030 - val_loss: 0.2761 - val_acc: 0.8967\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2662 - acc: 0.9004 - val_loss: 0.2896 - val_acc: 0.8929\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 9s 97ms/step - loss: 0.2649 - acc: 0.9026 - val_loss: 0.2889 - val_acc: 0.8929\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2620 - acc: 0.9028 - val_loss: 0.2754 - val_acc: 0.9003\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2557 - acc: 0.9054 - val_loss: 0.2775 - val_acc: 0.8990\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2624 - acc: 0.9008 - val_loss: 0.2674 - val_acc: 0.9031\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2607 - acc: 0.9028 - val_loss: 0.2743 - val_acc: 0.8987\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2552 - acc: 0.9058 - val_loss: 0.2729 - val_acc: 0.9013\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2564 - acc: 0.9049 - val_loss: 0.2640 - val_acc: 0.9040\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 9s 98ms/step - loss: 0.2563 - acc: 0.9048 - val_loss: 0.2642 - val_acc: 0.9022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1b05e6828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 47us/step\n",
      "Test loss: 0.17375172334\n",
      "Test accuracy: 0.93645\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with 3 Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.9953 - acc: 0.6309 - val_loss: 0.5837 - val_acc: 0.7801\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.5745 - acc: 0.7818 - val_loss: 0.4700 - val_acc: 0.8262\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.4888 - acc: 0.8166 - val_loss: 0.4151 - val_acc: 0.8507\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.4382 - acc: 0.8374 - val_loss: 0.3763 - val_acc: 0.8647\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.4047 - acc: 0.8513 - val_loss: 0.3503 - val_acc: 0.8738\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.3811 - acc: 0.8595 - val_loss: 0.3239 - val_acc: 0.8827\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.3562 - acc: 0.8709 - val_loss: 0.3096 - val_acc: 0.8866\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.3392 - acc: 0.8755 - val_loss: 0.2985 - val_acc: 0.8888\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.3278 - acc: 0.8800 - val_loss: 0.2909 - val_acc: 0.8958\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.3165 - acc: 0.8847 - val_loss: 0.2780 - val_acc: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1b0a6bb70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.3045 - acc: 0.8900 - val_loss: 0.2710 - val_acc: 0.9006\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2954 - acc: 0.8920 - val_loss: 0.2659 - val_acc: 0.9037\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2869 - acc: 0.8954 - val_loss: 0.2569 - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.2817 - acc: 0.8968 - val_loss: 0.2597 - val_acc: 0.9022\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2731 - acc: 0.9010 - val_loss: 0.2521 - val_acc: 0.9070\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.2682 - acc: 0.9017 - val_loss: 0.2427 - val_acc: 0.9089\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.2612 - acc: 0.9046 - val_loss: 0.2427 - val_acc: 0.9091\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.2546 - acc: 0.9064 - val_loss: 0.2392 - val_acc: 0.9109\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2481 - acc: 0.9090 - val_loss: 0.2363 - val_acc: 0.9124\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2461 - acc: 0.9087 - val_loss: 0.2288 - val_acc: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1bd476cc0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 55us/step\n",
      "Test loss: 0.194906186376\n",
      "Test accuracy: 0.929433333333\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 10s 110ms/step - loss: 0.4419 - acc: 0.8332 - val_loss: 0.3664 - val_acc: 0.8639\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.4092 - acc: 0.8454 - val_loss: 0.3488 - val_acc: 0.8682\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3877 - acc: 0.8566 - val_loss: 0.3434 - val_acc: 0.8740\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3787 - acc: 0.8579 - val_loss: 0.3272 - val_acc: 0.8812\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3684 - acc: 0.8620 - val_loss: 0.3148 - val_acc: 0.8816\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3575 - acc: 0.8661 - val_loss: 0.3125 - val_acc: 0.8810\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3512 - acc: 0.8685 - val_loss: 0.3132 - val_acc: 0.8830\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3476 - acc: 0.8702 - val_loss: 0.3154 - val_acc: 0.8830\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.3436 - acc: 0.8721 - val_loss: 0.3028 - val_acc: 0.8865\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3412 - acc: 0.8716 - val_loss: 0.2951 - val_acc: 0.8897\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3342 - acc: 0.8771 - val_loss: 0.2944 - val_acc: 0.8892\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.3387 - acc: 0.8736 - val_loss: 0.2949 - val_acc: 0.8892\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3287 - acc: 0.8774 - val_loss: 0.2910 - val_acc: 0.8913\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3218 - acc: 0.8797 - val_loss: 0.2845 - val_acc: 0.8898\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3255 - acc: 0.8770 - val_loss: 0.2842 - val_acc: 0.8915\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3188 - acc: 0.8802 - val_loss: 0.2802 - val_acc: 0.8966\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3178 - acc: 0.8831 - val_loss: 0.2826 - val_acc: 0.8946\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3121 - acc: 0.8833 - val_loss: 0.2894 - val_acc: 0.8880\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3176 - acc: 0.8806 - val_loss: 0.2776 - val_acc: 0.8969\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3076 - acc: 0.8846 - val_loss: 0.2733 - val_acc: 0.8965\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.3071 - acc: 0.8854 - val_loss: 0.2705 - val_acc: 0.8970\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.3102 - acc: 0.8845 - val_loss: 0.2699 - val_acc: 0.8983\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.3045 - acc: 0.8871 - val_loss: 0.2895 - val_acc: 0.8894\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3051 - acc: 0.8852 - val_loss: 0.2773 - val_acc: 0.8959\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.3056 - acc: 0.8869 - val_loss: 0.2739 - val_acc: 0.8943\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2996 - acc: 0.8882 - val_loss: 0.2637 - val_acc: 0.8981\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3006 - acc: 0.8879 - val_loss: 0.2746 - val_acc: 0.8935\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2923 - acc: 0.8914 - val_loss: 0.2644 - val_acc: 0.8993\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2960 - acc: 0.8891 - val_loss: 0.2684 - val_acc: 0.9001\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2939 - acc: 0.8906 - val_loss: 0.2947 - val_acc: 0.8838\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2917 - acc: 0.8918 - val_loss: 0.2508 - val_acc: 0.9074\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 9s 99ms/step - loss: 0.2883 - acc: 0.8919 - val_loss: 0.2648 - val_acc: 0.8958\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2936 - acc: 0.8903 - val_loss: 0.2546 - val_acc: 0.9044\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2864 - acc: 0.8924 - val_loss: 0.2553 - val_acc: 0.9049\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2871 - acc: 0.8924 - val_loss: 0.2515 - val_acc: 0.9030\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2818 - acc: 0.8948 - val_loss: 0.2553 - val_acc: 0.9059\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2849 - acc: 0.8953 - val_loss: 0.2476 - val_acc: 0.9075\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2857 - acc: 0.8922 - val_loss: 0.2623 - val_acc: 0.9049\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.2790 - acc: 0.8974 - val_loss: 0.2463 - val_acc: 0.9074\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2809 - acc: 0.8950 - val_loss: 0.2550 - val_acc: 0.9027\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2831 - acc: 0.8937 - val_loss: 0.2525 - val_acc: 0.9029\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2783 - acc: 0.8959 - val_loss: 0.2497 - val_acc: 0.9076\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2747 - acc: 0.8981 - val_loss: 0.2528 - val_acc: 0.9062\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.2769 - acc: 0.8955 - val_loss: 0.2540 - val_acc: 0.9039\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.2745 - acc: 0.8978 - val_loss: 0.2622 - val_acc: 0.8999\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2760 - acc: 0.8961 - val_loss: 0.2371 - val_acc: 0.9113\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2693 - acc: 0.9008 - val_loss: 0.2490 - val_acc: 0.9099\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.2726 - acc: 0.8990 - val_loss: 0.2532 - val_acc: 0.9046\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2666 - acc: 0.9014 - val_loss: 0.2386 - val_acc: 0.9094\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2705 - acc: 0.8979 - val_loss: 0.2471 - val_acc: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1c046c780>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 57us/step\n",
      "Test loss: 0.178289840607\n",
      "Test accuracy: 0.9329\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with 4 Convolutional Layers and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 10s 207us/step - loss: 0.7301 - acc: 0.7499 - val_loss: 0.4323 - val_acc: 0.8475\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.4324 - acc: 0.8433 - val_loss: 0.3779 - val_acc: 0.8635\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.3613 - acc: 0.8710 - val_loss: 0.3002 - val_acc: 0.8930\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.3175 - acc: 0.8860 - val_loss: 0.2724 - val_acc: 0.9030\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.2859 - acc: 0.8985 - val_loss: 0.2631 - val_acc: 0.9040\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.2609 - acc: 0.9071 - val_loss: 0.2533 - val_acc: 0.9073\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.2454 - acc: 0.9125 - val_loss: 0.2602 - val_acc: 0.9066\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.2256 - acc: 0.9191 - val_loss: 0.2261 - val_acc: 0.9203\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.2139 - acc: 0.9224 - val_loss: 0.2343 - val_acc: 0.9207\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.2050 - acc: 0.9259 - val_loss: 0.2249 - val_acc: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1d18bd6a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1911 - acc: 0.9320 - val_loss: 0.2040 - val_acc: 0.9266\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1811 - acc: 0.9359 - val_loss: 0.2089 - val_acc: 0.9266\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1727 - acc: 0.9372 - val_loss: 0.2067 - val_acc: 0.9283\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1607 - acc: 0.9409 - val_loss: 0.2021 - val_acc: 0.9304\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1554 - acc: 0.9442 - val_loss: 0.2232 - val_acc: 0.9219\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1486 - acc: 0.9461 - val_loss: 0.2044 - val_acc: 0.9315\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.1390 - acc: 0.9497 - val_loss: 0.2082 - val_acc: 0.9274\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1307 - acc: 0.9524 - val_loss: 0.2003 - val_acc: 0.9319\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.1243 - acc: 0.9547 - val_loss: 0.1955 - val_acc: 0.9324\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1217 - acc: 0.9559 - val_loss: 0.2254 - val_acc: 0.9262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1c0704a90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 98us/step\n",
      "Test loss: 0.101205606656\n",
      "Test accuracy: 0.964583333333\n"
     ]
    }
   ],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 10s 112ms/step - loss: 0.4079 - acc: 0.8583 - val_loss: 0.3191 - val_acc: 0.8868\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.3377 - acc: 0.8776 - val_loss: 0.2969 - val_acc: 0.8908\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.3030 - acc: 0.8909 - val_loss: 0.2915 - val_acc: 0.8930\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 10s 110ms/step - loss: 0.2968 - acc: 0.8916 - val_loss: 0.2750 - val_acc: 0.9002\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 11s 118ms/step - loss: 0.2869 - acc: 0.8972 - val_loss: 0.2848 - val_acc: 0.8955\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2782 - acc: 0.8987 - val_loss: 0.2478 - val_acc: 0.9098\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.2682 - acc: 0.9035 - val_loss: 0.2593 - val_acc: 0.9067\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 10s 105ms/step - loss: 0.2675 - acc: 0.9037 - val_loss: 0.2524 - val_acc: 0.9056\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.2585 - acc: 0.9059 - val_loss: 0.2294 - val_acc: 0.9163\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 10s 108ms/step - loss: 0.2590 - acc: 0.9079 - val_loss: 0.2724 - val_acc: 0.8983\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 10s 106ms/step - loss: 0.2548 - acc: 0.9070 - val_loss: 0.2416 - val_acc: 0.9104\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.2485 - acc: 0.9100 - val_loss: 0.2435 - val_acc: 0.9109\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2479 - acc: 0.9107 - val_loss: 0.2308 - val_acc: 0.9118\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.2443 - acc: 0.9120 - val_loss: 0.2625 - val_acc: 0.9062\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2453 - acc: 0.9109 - val_loss: 0.2314 - val_acc: 0.9142\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2385 - acc: 0.9136 - val_loss: 0.2545 - val_acc: 0.9085\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2344 - acc: 0.9164 - val_loss: 0.2224 - val_acc: 0.9177\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 10s 106ms/step - loss: 0.2336 - acc: 0.9160 - val_loss: 0.2708 - val_acc: 0.9006\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.2300 - acc: 0.9165 - val_loss: 0.2503 - val_acc: 0.9104\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 10s 104ms/step - loss: 0.2319 - acc: 0.9165 - val_loss: 0.2197 - val_acc: 0.9198\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2217 - acc: 0.9203 - val_loss: 0.2055 - val_acc: 0.9257\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 10s 105ms/step - loss: 0.2287 - acc: 0.9165 - val_loss: 0.2213 - val_acc: 0.9221\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2245 - acc: 0.9191 - val_loss: 0.2312 - val_acc: 0.9158\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 10s 103ms/step - loss: 0.2162 - acc: 0.9232 - val_loss: 0.2203 - val_acc: 0.9190\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 10s 107ms/step - loss: 0.2159 - acc: 0.9226 - val_loss: 0.2117 - val_acc: 0.9240\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.2174 - acc: 0.9214 - val_loss: 0.2200 - val_acc: 0.9204\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2191 - acc: 0.9200 - val_loss: 0.2170 - val_acc: 0.9207\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2114 - acc: 0.9234 - val_loss: 0.2062 - val_acc: 0.9255\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2119 - acc: 0.9231 - val_loss: 0.2243 - val_acc: 0.9185\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.2096 - acc: 0.9233 - val_loss: 0.2133 - val_acc: 0.9238\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2047 - acc: 0.9268 - val_loss: 0.2047 - val_acc: 0.9256\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2043 - acc: 0.9270 - val_loss: 0.2141 - val_acc: 0.9231\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 9s 100ms/step - loss: 0.2105 - acc: 0.9242 - val_loss: 0.2078 - val_acc: 0.9245\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.2028 - acc: 0.9273 - val_loss: 0.2151 - val_acc: 0.9220\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.2002 - acc: 0.9295 - val_loss: 0.2032 - val_acc: 0.9254\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1986 - acc: 0.9281 - val_loss: 0.1965 - val_acc: 0.9311\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1968 - acc: 0.9283 - val_loss: 0.2355 - val_acc: 0.9171\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1997 - acc: 0.9281 - val_loss: 0.2155 - val_acc: 0.9243\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1918 - acc: 0.9309 - val_loss: 0.2305 - val_acc: 0.9214\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1933 - acc: 0.9306 - val_loss: 0.1951 - val_acc: 0.9302\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1922 - acc: 0.9314 - val_loss: 0.2082 - val_acc: 0.9232\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1869 - acc: 0.9323 - val_loss: 0.2040 - val_acc: 0.9271\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1947 - acc: 0.9309 - val_loss: 0.2225 - val_acc: 0.9222\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1873 - acc: 0.9336 - val_loss: 0.2000 - val_acc: 0.9280\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1866 - acc: 0.9325 - val_loss: 0.1929 - val_acc: 0.9296\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1846 - acc: 0.9332 - val_loss: 0.1984 - val_acc: 0.9285\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 0.1840 - acc: 0.9337 - val_loss: 0.2080 - val_acc: 0.9258\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1838 - acc: 0.9334 - val_loss: 0.1971 - val_acc: 0.9292\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 10s 102ms/step - loss: 0.1849 - acc: 0.9337 - val_loss: 0.1980 - val_acc: 0.9289\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 9s 101ms/step - loss: 0.1837 - acc: 0.9347 - val_loss: 0.2039 - val_acc: 0.9292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1db5be7f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 94us/step\n",
      "Test loss: 0.101326133166\n",
      "Test accuracy: 0.96415\n"
     ]
    }
   ],
   "source": [
    "score = cnn3.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('fashion_mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "model = load_model('fashion_mnist.h5')\n",
    "\n",
    "#cnn3.compile(loss='sparse_categorical_crossentropy',\n",
    " #             optimizer=Adam(lr=0.001),\n",
    "  #            metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread(r'C:\\\\Users\\Mustafa\\Jupyter Notebook work\\CNN Learning\\test_images\\tro.jpg',0)\n",
    "img = cv2.resize(img,(1,784))\n",
    "img = np.reshape(img,[1,784])\n",
    "\n",
    "classes = model.predict_classes(img)\n",
    "\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
